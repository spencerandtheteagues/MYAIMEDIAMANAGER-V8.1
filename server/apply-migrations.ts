#!/usr/bin/env tsx
import { pool, db } from "./db";
import { sql } from "drizzle-orm";
import fs from "fs/promises";
import path from "path";

const MIGRATION_DIR = path.join(process.cwd(), "migrations");

async function fileExists(filePath: string): Promise<boolean> {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}

async function runMigration(migrationFile: string): Promise<void> {
  const filePath = path.join(MIGRATION_DIR, migrationFile);

  if (!await fileExists(filePath)) {
    throw new Error(`Migration file not found: ${filePath}`);
  }

  console.log(`\nðŸ“‹ Reading migration: ${migrationFile}`);
  const migrationSQL = await fs.readFile(filePath, "utf-8");

  // Split by statements (simple approach - may need refinement for complex SQL)
  const statements = migrationSQL
    .split(";")
    .map(s => s.trim())
    .filter(s => s.length > 0 && !s.startsWith("--"));

  console.log(`   Found ${statements.length} SQL statements to execute`);

  const startTime = Date.now();
  let successCount = 0;
  let skipCount = 0;

  for (let i = 0; i < statements.length; i++) {
    const statement = statements[i] + ";";

    // Skip ANALYZE statements for now as they're not critical
    if (statement.toUpperCase().includes("ANALYZE ")) {
      console.log(`   â­ï¸  Skipping ANALYZE statement ${i + 1}/${statements.length}`);
      skipCount++;
      continue;
    }

    try {
      await pool.query(statement);
      successCount++;

      // Log progress for long migrations
      if ((i + 1) % 10 === 0 || i === statements.length - 1) {
        console.log(`   âœ… Executed ${successCount} statements (${i + 1}/${statements.length})`);
      }
    } catch (error: any) {
      // Ignore "already exists" errors for idempotent migrations
      if (error.message?.includes("already exists") ||
          error.message?.includes("duplicate key") ||
          error.code === "42P07" || // relation already exists
          error.code === "42P01" || // undefined table (for DROP IF EXISTS)
          error.code === "42710") { // duplicate object
        skipCount++;
        continue;
      }

      console.error(`   âŒ Error executing statement ${i + 1}:`, error.message);
      throw error;
    }
  }

  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  console.log(`   âœ… Migration completed: ${successCount} executed, ${skipCount} skipped (${duration}s)`);
}

async function testPerformance(): Promise<void> {
  console.log("\nðŸ” Testing query performance improvements...");

  const tests = [
    {
      name: "User lookup by email",
      query: "SELECT id, email, username FROM users WHERE email = $1 LIMIT 1",
      params: ["admin@myaimediamgr.com"]
    },
    {
      name: "Campaign listing with status",
      query: "SELECT id, name, status FROM campaigns WHERE user_id = $1 AND status = $2 LIMIT 10",
      params: ["admin-user-1", "active"]
    },
    {
      name: "Scheduled posts query",
      query: "SELECT id, content, scheduled_for FROM posts WHERE user_id = $1 AND scheduled_for > NOW() ORDER BY scheduled_for LIMIT 20",
      params: ["admin-user-1"]
    },
    {
      name: "Credit transactions history",
      query: "SELECT id, amount, type, created_at FROM credit_transactions WHERE user_id = $1 ORDER BY created_at DESC LIMIT 50",
      params: ["admin-user-1"]
    },
    {
      name: "Analytics aggregation",
      query: "SELECT platform, COUNT(*) as count, AVG(value) as avg_value FROM analytics WHERE user_id = $1 AND date >= NOW() - INTERVAL '30 days' GROUP BY platform",
      params: ["admin-user-1"]
    }
  ];

  console.log("\n   Running performance tests...");
  const results: any[] = [];

  for (const test of tests) {
    try {
      const startTime = Date.now();
      await pool.query(test.query, test.params);
      const duration = Date.now() - startTime;

      results.push({
        test: test.name,
        duration: `${duration}ms`,
        status: duration < 100 ? "ðŸš€ Fast" : duration < 500 ? "âœ… Good" : "âš ï¸ Slow"
      });
    } catch (error: any) {
      results.push({
        test: test.name,
        duration: "N/A",
        status: "âŒ Failed"
      });
    }
  }

  console.log("\nðŸ“Š Performance Test Results:");
  console.table(results);
}

async function main() {
  try {
    console.log("ðŸš€ MyAiMediaManager Database Migration Runner");
    console.log("============================================");

    // Test database connection
    console.log("\nðŸ”Œ Testing database connection...");
    const testResult = await pool.query("SELECT version()");
    const pgVersion = testResult.rows[0]?.version || "Unknown";
    console.log(`   âœ… Connected to PostgreSQL: ${pgVersion.split(" ").slice(0, 2).join(" ")}`);

    // Check if tables exist
    const tableCheck = await pool.query(`
      SELECT tablename FROM pg_tables
      WHERE schemaname = 'public'
      ORDER BY tablename
    `);
    console.log(`   ðŸ“¦ Found ${tableCheck.rows.length} existing tables`);

    // Apply migrations in order
    console.log("\nðŸ”„ Applying migrations in sequence...");

    // Migration 1: Performance Indexes
    console.log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("Migration 1: Performance Indexes (45+ indexes)");
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    await runMigration("0003_performance_indexes.sql");

    // Migration 1.5: Clean up invalid tier values
    console.log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("Migration 1.5: Data Cleanup - Fix Invalid Tier Values");
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    await runMigration("0003a_cleanup_tier_values.sql");

    // Migration 2: Data Integrity Constraints
    console.log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("Migration 2: Data Integrity Constraints (30+ constraints)");
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    await runMigration("0004_data_integrity_constraints.sql");

    // Migration 3: Security Audit Tables
    console.log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("Migration 3: Security Audit Tables");
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    await runMigration("0005_security_audit_tables.sql");

    // Test performance improvements
    await testPerformance();

    // Final summary
    console.log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("âœ¨ All migrations applied successfully!");
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    console.log("\nðŸŽ¯ Expected improvements:");
    console.log("   â€¢ 10-100x faster query performance");
    console.log("   â€¢ Enhanced data integrity with business rule constraints");
    console.log("   â€¢ Complete audit trail for security compliance");
    console.log("   â€¢ Optimized indexes for common query patterns");
    console.log("   â€¢ Automatic timestamp updates via triggers");

    // Check final index count
    const indexCount = await pool.query(`
      SELECT COUNT(*) as count
      FROM pg_indexes
      WHERE schemaname = 'public'
    `);
    console.log(`\nðŸ“ˆ Total indexes in database: ${indexCount.rows[0].count}`);

    process.exit(0);
  } catch (error) {
    console.error("\nâŒ Migration failed:", error);
    process.exit(1);
  }
}

// Export main function for server integration
export { main };

// Run migrations if this file is executed directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch(console.error);
}